# Lab 2.3: Auto RAG

## Auto RAG
Congratulations we already create the data connection. Now we want to build auto RAG, click assets 

![alt text](image/image-14.png)

Search `building in machine learning or RAG solutions automatically` in the assets menu

![alt text](image/image-15.png)

Fill the `Name` field such as follows 

![alt text](image/image-16.png)

For the documents that needed to be upload, we choose `select from project` . Choose connection that we already create from previous steps

![alt text](image/image-7.png)

Choose some of the documents in Object Storage. This is the displayed od documents that needed to processing

![alt text](image/image-17.png)

Scroll down, in here we can find how we want to store the database vector, watsonx can be integrated with milvus, chromaDB, etc. In this case we will use in memory vector, we dont connect it to milvus/chromaDB/elastic.

![alt text](image/image-19.png)

Run the experiment

![alt text](image/image-23.png)

The Auto RAG will load and evaluate which metric configuration is the best to use. It will also rank which pipeline performs best.

![alt text](image/image-24.png)

Open the pipeline that performs best, and then compare it with the others. Here, we can see pattern information such as the configuration of the vector store, chunking, embeddings, retrieval, generation, and even the sample QnA pairs.

![alt text](image/image-25.png)

We can also choose which metric ranking we would like to see, whether it is based on correct answers, context correctness, or answer faithfulness.

![alt text](image/image-26.png)

## Turn the model into AI Services
We can save the configuration and reuse it by saving the pipeline, as shown here

![alt text](image/image-27.png)

We can save it as a notebook or as an AI service; in this case, I will save it as an AI service.

![alt text](image/image-28.png)

Add the deployment space where we want to deploy the AI service, such as this.

![alt text](image/image-29.png)

The AI service is already deployed, such as this.

![alt text](image/image-30.png)

The AI Services can be consume through API with Curl, JavaScript, Python, etc 

![alt text](image/image-31.png)

We can also do testing by choose `preview menu`. 
Sample Questions you could try
1. How to retrieve the list of model lifecycle data?
2. How to install ibm-watsonx-ai library?
3. How to retrieve the list of model lifecycle data?
4. What is method for get model inferance details?
5. How to get IAM APIkey

![alt text](image/image-32.png)

