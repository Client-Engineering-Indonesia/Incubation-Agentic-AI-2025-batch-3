# Create Project in Langflow

## 1. Open Langflow
#### Refer to [Lab 0 - Environment Setup](../Lab%200%20-%20Environment%20Setup/README.md) to set up and access Langflow.


## 2. Create a Project

1. In Langflow, click **"Create First Project"** or **"New Project"**.
<img width="1440" height="900" alt="Screenshot 2025-07-17 at 11 27 05" src="https://github.com/user-attachments/assets/8e29b353-7b9c-48a2-a9e6-4f420c105b69" />

2. From the template options, select **Vector Store RAG**
<img width="1440" height="900" alt="Screenshot 2025-07-17 at 11 27 17" src="https://github.com/user-attachments/assets/65572f10-1101-421c-ba9f-ce75767eab49" />

> [!NOTE]
> ### ‚ÑπÔ∏è What is Vector Store RAG?
> ![image-16 (1)](https://github.com/user-attachments/assets/045edd18-69c6-4c38-8126-9bdb47010174)
>
> **RAG** stands for **Retrieval-Augmented Generation**, a method to make AI more accurate by giving it the right information before it answers.
>
> - **Retrieval** ‚Äî The system searches your data (like PDFs, documents, or webpages) to find the most relevant pieces using **vector similarity**.
> - **Augmented** ‚Äî These results are then **added to the prompt or context** that the AI sees.
> - **Generation** ‚Äî The language model (LLM) uses both your question and the retrieved info to generate a better, more informed answer.
>
> A **vector store** (like AstraDB, ChromaDB, Elasticsearch, etc.) acts as a **specialized database** that stores your data as **embeddings** (mathematical representations of meaning), enabling fast and smart retrieval based on similarity ‚Äî not just keywords.

3. After selecting the template, rename your project to include your **name or initials**
<img width="1440" height="900" alt="Screenshot 2025-07-17 at 11 40 02" src="https://github.com/user-attachments/assets/293bb04c-733b-4410-ac4f-a4273f27f557" />

## 3. Explore the Vector Store RAG Template
<img width="1162" height="721" alt="Screenshot 2025-07-17 at 17 19 53" src="https://github.com/user-attachments/assets/1393cb0e-7e1a-4dd8-a183-d534eb719a98" />

Once your project is created, you'll notice the template contains **two flows**:
#### üìö 1. Load Data Flow

This flow is responsible for:
- Taking input documents
- Splitting them into chunks
- Creating **embeddings** using OpenAI
- Storing those embeddings into a **vector database** (AstraDB in this default case)

#### üêï  2. Retriever Flow

This is the "inference" flow:
- Accepts user questions
- Uses semantic similarity to **retrieve relevant chunks** from the vector database
- Combines retrieved context with the user question
- Sends it to an **LLM** to generate a response

### Customization for This Lab

In this lab, we will **customize the RAG flow** to use:

- **watsonx.ai** as the **LLM**
- **Elasticsearch** as the **vector store**

> [!NOTE]
> ### ü§ñ What is watsonx.ai?
> 
> **[watsonx.ai](https://www.ibm.com/watsonx/ai)** is IBM‚Äôs powerful AI platform designed to help businesses build, train, and deploy **foundation models** and **machine learning models** at scale.
> 
> #### üîß Key Features:
> - Access to both **open-source** and **IBM-trained foundation models**
> - Tools for **fine-tuning** models using your own data
> - Easy-to-use interface for **prompt engineering** and testing
> - Works seamlessly with **watsonx.data** for data storage and **AI governance** for compliance
> - Built with enterprise needs in mind. Ideal for **regulated industries** like finance, healthcare, and government
> 
> In this lab, we‚Äôll use watsonx.ai as the **LLM (Large Language Model)** to generate answers using the user‚Äôs question and relevant information retrieved from your data.

> [!NOTE]
> ### üîç What is Elasticsearch?
> 
> **[Elasticsearch](https://www.elastic.co/elasticsearch/)** is a powerful search engine that helps you quickly find and analyze data.
> 
> It‚Äôs commonly used for:
> - Searching through large amounts of text
> - Analyzing logs and real-time data
> - Finding similar meanings using **vector search**
> 
> Apps like **Netflix**, **Spotify**, and **Wikipedia** use Elasticsearch to power their search features ‚Äî for example, to help users find relevant movies, songs, or articles instantly.
> 
> #### üß† Why Use It in RAG?
> 
> In a **RAG (Retrieval-Augmented Generation)** setup, Elasticsearch is used to:
> - Store your documents as **embeddings** (meaning-based representations)
> - Quickly find the most relevant pieces of information for a question
> - Send that info to an AI model so it can give smarter answers
> 
> Because it supports **vector search**, Elasticsearch works well with modern AI tools.

[‚û°Ô∏è Move to Next Page: Create Index in Elastic Search](./2.%20Create%20Index%20in%20Elastic%20Search.md)
